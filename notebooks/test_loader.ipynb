{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T18:53:35.649843Z",
     "start_time": "2024-07-06T18:53:34.993561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Iterator\n",
    "\n",
    "from backend.parser import rustore_docs_extractor\n",
    "\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain_community.document_loaders import SitemapLoader\n",
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ],
   "id": "456ad44ffa298011",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T18:54:05.693105Z",
     "start_time": "2024-07-06T18:54:05.689449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ],
   "id": "e16a366334b65c9e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T18:54:47.017880Z",
     "start_time": "2024-07-06T18:54:47.013444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "id": "27c7eb3427cdbe1e",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-06T18:58:24.027051Z",
     "start_time": "2024-07-06T18:58:24.017711Z"
    }
   },
   "source": [
    "class SitemapLoaderWithChromium(SitemapLoader):\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        \"\"\"Load sitemap.\"\"\"\n",
    "        if self.is_local:\n",
    "            try:\n",
    "                import bs4\n",
    "            except ImportError:\n",
    "                raise ImportError(\n",
    "                    \"beautifulsoup4 package not found, please install it\"\n",
    "                    \" with `pip install beautifulsoup4`\"\n",
    "                )\n",
    "            fp = open(self.web_path)\n",
    "            soup = bs4.BeautifulSoup(fp, \"xml\")\n",
    "        else:\n",
    "            soup = self._scrape(self.web_path, parser=\"xml\")\n",
    "\n",
    "        els = self.parse_sitemap(soup)\n",
    "\n",
    "        results = self.scrape_all([el[\"loc\"].strip() for el in els if \"loc\" in el])\n",
    "\n",
    "        for i, result in enumerate(results):\n",
    "            text_content = self.parsing_function(result, els[i][\"loc\"])\n",
    "            yield Document(\n",
    "                page_content=text_content,\n",
    "                metadata=self.meta_function(els[i], result, text_content),\n",
    "            )\n",
    "\n",
    "    async def _fetch(\n",
    "            self, url: str, retries: int = 3, cooldown: int = 2, backoff: float = 1.5\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Asynchronously scrape the content of a given URL using Playwright's async API.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL to scrape.\n",
    "\n",
    "        Returns:\n",
    "            str: The scraped HTML content or an error message if an exception occurs.\n",
    "\n",
    "        \"\"\"\n",
    "        from playwright.async_api import async_playwright\n",
    "\n",
    "        logger.info(\"Starting scraping...\")\n",
    "        results = \"\"\n",
    "        async with async_playwright() as p:\n",
    "            browser = await p.chromium.launch(headless=True)\n",
    "            try:\n",
    "                page = await browser.new_page()\n",
    "                await page.goto(url)\n",
    "                results = await page.content()  # Simply get the HTML content\n",
    "                logger.info(\"Content scraped\")\n",
    "            except Exception as e:\n",
    "                results = f\"Error: {e}\"\n",
    "            await browser.close()\n",
    "        return results\n",
    "\n",
    "\n",
    "def metadata_extractor(meta: dict, soup: BeautifulSoup, text_content: str) -> dict:\n",
    "    title = soup.find(\"title\")\n",
    "    crumbs = text_content.split('\\n')[0]\n",
    "    description = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    html = soup.find(\"html\")\n",
    "    return {\n",
    "        \"crumbs\": crumbs,\n",
    "        \"source\": meta[\"loc\"],\n",
    "        \"title\": title.get_text() if title else crumbs,\n",
    "        \"description\": description.get(\"content\", \"\") if description else \"\",\n",
    "        \"language\": html.get(\"lang\", \"\") if html else \"\",\n",
    "        **meta,\n",
    "    }"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T18:58:26.260467Z",
     "start_time": "2024-07-06T18:58:26.255883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_rustore_docs():\n",
    "    file_path = Path(\"../data/sitemap-help.xml\").absolute()\n",
    "    return SitemapLoaderWithChromium(\n",
    "        file_path,\n",
    "        is_local=True,\n",
    "        filter_urls=[\"https://www.rustore.ru/help/sdk/payments/react\"],\n",
    "        parsing_function=rustore_docs_extractor,\n",
    "        default_parser=\"lxml\",\n",
    "        bs_kwargs={\n",
    "            \"parse_only\": SoupStrainer(\n",
    "                name=(\"article\", \"title\", \"html\", \"lang\", \"content\")\n",
    "            ),\n",
    "        },\n",
    "        meta_function=metadata_extractor,\n",
    "        requests_per_second=1,\n",
    "    ).load()"
   ],
   "id": "b38198057615f98",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T18:58:33.975510Z",
     "start_time": "2024-07-06T18:58:28.015541Z"
    }
   },
   "cell_type": "code",
   "source": "docs = load_rustore_docs()",
   "id": "575b14f94a7776a0",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T19:35:21.454999Z",
     "start_time": "2024-07-06T19:35:21.449290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_docs_by_markdown(_docs: [Document]):\n",
    "    from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "    \n",
    "    headers_to_split_on = [(\"##\", \"header\")]\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "    \n",
    "    pattern = r\"#[\\w-]+\"\n",
    "    \n",
    "    docs_to_return = []\n",
    "    \n",
    "    for doc in _docs:\n",
    "        new_docs = markdown_splitter.split_text(doc.page_content)\n",
    "        \n",
    "        for _new_doc in new_docs:\n",
    "            _new_doc.metadata |= doc.metadata\n",
    "            \n",
    "            if _new_doc.metadata.get('header'):\n",
    "                anchor = re.findall(pattern, _new_doc.metadata[\"header\"])[0]\n",
    "                _new_doc.metadata |= dict(source=f'{doc.metadata[\"source\"]}/{anchor}')\n",
    "        \n",
    "        docs_to_return.extend(new_docs)\n",
    "    \n",
    "    return docs_to_return"
   ],
   "id": "b6fcb178a8299c19",
   "execution_count": 48,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T19:35:23.744321Z",
     "start_time": "2024-07-06T19:35:23.737282Z"
    }
   },
   "cell_type": "code",
   "source": "transformed_docs = split_docs_by_markdown(docs)",
   "id": "3ff737f5285cdff5",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T19:35:38.681889Z",
     "start_time": "2024-07-06T19:35:38.677746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for doc in transformed_docs:\n",
    "    print(doc.metadata)"
   ],
   "id": "6855a8d76bf46084",
   "execution_count": 51,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
